<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<meta name="description" content="_your description goes here_" />
<meta name="keywords" content="_your,keywords,goes,here_" />
<meta name="author" content="_your name goes here_  / Original design: Andreas Viklund - http://andreasviklund.com/" />
<link rel="stylesheet" type="text/css" href="andreas01.css" media="screen" title="andreas01 (screen)" />
<link rel="stylesheet" type="text/css" href="print.css" media="print" />
<title>Allan's Homepage</title>
</head>

<body><div id="wrap">

<div id="header">
</div>

<img id="frontphoto" src="logo.png" width="760" height="175" alt="" />

<div id="avmenu">
<h2 class="hide">Menu:</h2>
<ul>
<li><a href="index.html">Home</a></li>
<li><a href="award.html">News</a></li>
<li><a href="publication.html">Full Publication</a></li>
<li><a href="service.html">Service</a></li>
<li><a href="award.html">Award</a></li>
</ul>


<!-- <div class="announce">
<h3>Latest news:</h3>
<p><strong>May 4, 2015:</strong><br />
The program details are online available now.</font></p>
<p><strong>Mar. 3, 2015:</strong><br />
The submission deadline has been extended to <font color="red"> Mar. 16</font>.</p>
<p><strong>Jan. 21, 2015:</strong><br />
The CMT submission website is online.</p>
<p class="textright"><a href="index.html">Read more...</a></p>
</div>
 -->
</div>



<div id="extras">
<h3>Links:</h3>
<p><a href="https://scholar.google.com/citations?user=TKbyRRsAAAAJ&hl=en" target="_blank">Google Scholar</a><p>
<p><a href="http://dblp.uni-trier.de/pers/hd/d/Ding:Zhengming" target="_blank">DBLP</a><p>
<p><a href="https://www.linkedin.com/feed/?trk=nav_logo" target="_blank">LinkedIn</a><p>

 </div>


<!-- <div id="extras">
<h3>Invited Speakers:</h3>
<p><a href="http://www3.nd.edu/~kwb/" target="_blank">Kevin W. Bowyer</a><p>
<p><a href="https://billf.mit.edu/" target="_blank">Bill Freeman</a><p>
<p><a href="http://www.ecse.rpi.edu/~qji/" target="_blank">Qiang Ji</a><p>
<h3>Sponsors:</h3>
<img src="cvf.png" alt="" width="50" height="32"/> 
<p><p>
<img src="IEEE_Boston.png" alt="" width="110" height="30"/>
<p><p>
<img src="ieee_cs.png" alt="" width="100" height="35"/> 
 </div> -->

<div id="content">
  <h5>Welcome to Allan's Homepage</h5>
  
  <p3><em>Embracing Face and Gesture Analysis in Social Media with Deep Learning</em></p3>
  <p>Deep learning, especially the Convolutional Neural Networks have taken the computer vision community by storm, significantly improving the state of the art in many applications. Among them, face recognition, which has accumulated large quantities of training data in the past few decades due to the availability of online resources as well as dedicated efforts of many researchers, has been dramatically changed on the strength of the new/efficient deep learning models, and we still witness this consistent streams of record breaking improvements in many benchmarks, e.g., La-beled Faces in the Wild database (LFW), YouTube Faces database, most recently, CASIA Web-Face, MegaFace, MS-Celeb-1M, and real-world or commercial systems. </p>

  <p>Besides the efforts putting forward to the conventional face recognition research, visual under-standing of social media content has attracted the interest of industrial and academic research communities from different domains. Visual understanding of social media includes face and body tracking (e.g., facial expression analysis, face detection, gesture recognition), facial and body characteristic analysis (e.g., gait, age, gender, and ethnicity), human behavior understanding and emotion recognition from face and gesture, social context understanding (e.g., kinship, personality, and beauty) and visual sentiment analysis. Creating effective models under visual uncertainty has significant scientific and practical values in applications of human-computer interaction, social media analytics, video indexing, visual surveillance, and Internet vision. To that end, researchers have made substantial progress, especially when off-the-shelf vision products are available, e.g. Kinect, Leap, SHORE, and Affdex. However, great challenges remain in the social media domain, especially under unconstrained imaging conditions from diverse sources with non-cooperative users. Here, we are especially interested in bringing in the cutting-edge techniques and recent advances in deep learning to solve the challenges above in social media.</p>
  
</div>

<div id="footer">
Copyright &copy; 2017 <a href="http://www.northeastern.edu/smilelab/">SMILE Lab</a>, Northeastern University.
</div>

</div>
</body>
</html>
