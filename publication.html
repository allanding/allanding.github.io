<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<meta name="description" content="_your description goes here_" />
<meta name="keywords" content="_your,keywords,goes,here_" />
<meta name="author" content="_your name goes here_  / Original design: Andreas Viklund - http://andreasviklund.com/" />
<link rel="stylesheet" type="text/css" href="andreas01.css" media="screen" title="andreas01 (screen)" />
<link rel="stylesheet" type="text/css" href="print.css" media="print" />
<title>Allan's Homepage</title>
</head>

<body><div id="wrap">

<div id="header">
</div>

<img id="frontphoto" src="logo.png" width="760" height="175" alt="" />

<div id="avmenu">
<h2 class="hide">Menu:</h2>
<ul>
<li><a href="index.html">Home</a></li>
<li><a href="research.html">Research</a></li>

<li><a href="award.html">News</a></li>
<li><a href="publication.html">Full Publication</a></li>
<li><a href="service.html">Service</a></li>
<li><a href="award.html">Award</a></li>
</ul>


<!-- <div class="announce">
<h3>Latest news:</h3>
<p><strong>May 4, 2015:</strong><br />
The program details are online available now.</font></p>
<p><strong>Mar. 3, 2015:</strong><br />
The submission deadline has been extended to <font color="red"> Mar. 16</font>.</p>
<p><strong>Jan. 21, 2015:</strong><br />
The CMT submission website is online.</p>
<p class="textright"><a href="index.html">Read more...</a></p>
</div>
 -->
</div>



<div id="extras">
<h3>Links:</h3>
<p><a href="https://scholar.google.com/citations?user=TKbyRRsAAAAJ&hl=en" target="_blank">Google Scholar</a><p>
<p><a href="http://dblp.uni-trier.de/pers/hd/d/Ding:Zhengming" target="_blank">DBLP</a><p>
<p><a href="https://www.linkedin.com/feed/?trk=nav_logo" target="_blank">LinkedIn</a><p>

 </div>

<!-- <div id="extras">
<h3>Invited Speakers:</h3>
<p><a href="http://www3.nd.edu/~kwb/" target="_blank">Kevin W. Bowyer</a><p>
<p><a href="https://billf.mit.edu/" target="_blank">Bill Freeman</a><p>
<p><a href="http://www.ecse.rpi.edu/~qji/" target="_blank">Qiang Ji</a><p>
<h3>Sponsors:</h3>
<img src="cvf.png" alt="" width="50" height="32"/> 
<p><p>
<img src="ICCVLogo_alpha.png" alt="" width="110" height="30"/>
<p><p>
<img src="ieee_cs.png" alt="" width="100" height="35"/> 
 </div> -->

<div id="content">
  <h5>Call For Papers</h5>
  <p3><em>Embracing Face and Gesture Analysis in Social Media with Deep Learning</em></p3>
  <p>This one-day serial workshop (AMFG2017) will provide a forum for researchers to review the recent progress of recognition, analysis and modeling of face, gesture, and body, and embrace the most advanced deep learning system to address face and gesture analysis particularly under unconstrained environment such as social media. The workshop will consist of one to two invited talks; one from industry, together with peer-reviewed regular papers (oral and poster). Original high-quality contributions are solicited on the following topics: </p>

<p>1. Deep learning methodology, theory, and its applications to social media analytics;<p>

<p>2. Novel deep learning model, deep learning survey, or comparative study for face/gesture recognition;<p>

<p>3. Deep learning for internet-scale soft biometrics and profiling: age, gender, ethnicity, personality, kinship, occupation, beauty, and fashion classification by facial and/or body descriptor;<p>

<p>4.	Face, gait, and action recognition in low-quality (blurred for instance), or low-resolution video from fixed or mobile cameras;<p>

<p>5.	Novel mathematical modeling and algorithms, sensors and modalities for face & body gesture/action representation, analysis and recognition for cross-domain social media;<p>

<p>6. Deep learning for detection and recognition of face and body in the wild with large 3D rotation, illumination change, partial occlusion, unknown/changing background, and aging; especially large 3D rotation robust face and gesture recognition;<p>

<p>7. Motion analysis, tracking and extraction of face and body models from image sequences captured by mobile devices;<p>

<p>8. Face, gait, and action recognition in low-quality (blurred for instance), or low-resolution video from fixed or mobile cameras;<p>

<p>9. Novel mathematical modeling and algorithms, sensors and modalities for face & body gesture/action representation, analysis, and recognition for cross-domain social media;<p>

<p>10. Social/Psychological studies that can assist in understanding computational modeling and building better automated face and gesture systems for interaction purposes;</p>

<p>11. Novel social applications based on the robust detection, tracking and recognition of face, body, and action;</p>

<p>12. Face and gesture analysis for sentiment analysis in social media;</p>
<p>13. Other applications of face and gesture analysis in social media content understanding.</p>
<p>
</div>

<div id="footer">
Copyright &copy; 2017 <a href="http://www.northeastern.edu/smilelab/">SMILE Lab, Northeastern University.</a>.
</div>

</div>
</body>
</html>
